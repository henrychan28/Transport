{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import copy\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRMSE(predictions, measures):\n",
    "    if(len(predictions)!=len(measures)):\n",
    "        raise ValueException('The array size of predictions and measures should be the same')\n",
    "    n = len(predictions)\n",
    "    squareErr = 0\n",
    "    for idx in range(n):\n",
    "        squareErr += (predictions[idx]-measures[idx])**2\n",
    "    print(squareErr)\n",
    "    squareErr = math.sqrt(squareErr/float(n))\n",
    "    return squareErr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMAE(predictions, measures):\n",
    "    if(len(predictions)!=len(measures)):\n",
    "        raise ValueException('The array size of predictions and measures should be the same')\n",
    "    n = len(predictions)\n",
    "    MAE = 0\n",
    "    for idx in range(n):\n",
    "        MAE += abs(predictions[idx] - measures[idx])\n",
    "    MAE /= n\n",
    "    return MAE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertTimeforExperiment(time):\n",
    "    return time.split(' ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPathDepth(directory='.'):\n",
    "    MAX_DEPTH = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        MAX_DEPTH = max(MAX_DEPTH, root.count(os.sep))\n",
    "    return MAX_DEPTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FileNode:\n",
    "    def __init__(self, folderName, fileName, nodeData, state=1, nextNode=None, restore=False):\n",
    "        self.__state = state\n",
    "        self.__fileName = fileName\n",
    "        self.__filePointer = folderName + '\\\\' + fileName\n",
    "        if not restore:\n",
    "            self.__dumpData(folderName, nodeData)\n",
    "            \n",
    "    def attemptReplace(self):\n",
    "        if self.__state == 1:\n",
    "            self.__state = 0\n",
    "            return False\n",
    "        elif self.__state == 0:\n",
    "            self.__state = -1\n",
    "            return True\n",
    "        else:\n",
    "            raise ValueError('FileNode[{0}] in invalid state {1}'.format(self.__fileName,self.__state))\n",
    "          \n",
    "    def updateFileNode(self, newNode):\n",
    "        self.__filePointer = newNode.__filePointer\n",
    "        self.__fileName = newNode.__fileName\n",
    "        self.__state = 1\n",
    "        return self.getFileInfo()\n",
    "\n",
    "    def getFileInfo(self):\n",
    "        return self.__fileName, self.__filePointer\n",
    "\n",
    "\n",
    "    def getData(self):\n",
    "        self.__state = 1\n",
    "        with open(self.__filePointer, 'r') as f:\n",
    "            return pickle.load(f)\n",
    "        \n",
    "    def __dumpData(self, folderName, data):\n",
    "        with open('{0}/{1}'.format(folderName, self.__fileName), 'w') as f:\n",
    "            pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FolderSystem:\n",
    "\n",
    "    def __init__(self, folderName, cacheLimit, restore = True):\n",
    "        #print('Constructing folder [{0}] with cacheLimit [{1}]'.format(folderName, cacheLimit))\n",
    "        if (cacheLimit<10):\n",
    "            raise ValueError('Please enter a limit larger than 10...')\n",
    "        #print(\"Constructing foldersystem for [{0}]\".format(folderName))\n",
    "        self.__folderName = folderName\n",
    "        self.__fileNodes = []\n",
    "        self.__fileNodesDict = dict()\n",
    "        self.__nodeNumLimit = cacheLimit\n",
    "        self.__numofNode = 0\n",
    "        self.__nodePointer = 0\n",
    "        if restore:\n",
    "            self.__folderBuilder(limit = cacheLimit)\n",
    "        self.__saveFolderSystem()\n",
    "        \n",
    "    def __folderBuilder(self, limit = 100):\n",
    "        self.__cleanUpExcessFile(limit)\n",
    "        for root, _, files in os.walk(\".\"): \n",
    "            if(self.__folderName == root):\n",
    "                for fileName in files:\n",
    "                    if \"cacheFolderSystem\" in fileName:\n",
    "                        continue\n",
    "                    self.addNode(fileName, None, restore = True)\n",
    "\n",
    "    def __cleanUpExcessFile(self, limit):\n",
    "        for root, _, files in os.walk(\".\"): \n",
    "            if(self.__folderName == root):\n",
    "                for idx, fileName in enumerate(files):\n",
    "                    if \"cacheFolderSystem\" in fileName:\n",
    "                        limit += 1\n",
    "                        continue\n",
    "                    if idx >= limit:\n",
    "                        os.remove(self.__folderName + '\\\\' + fileName)\n",
    "    \n",
    "    def addNode(self, fileName, nodeData, restore = False):\n",
    "        if fileName in self.__fileNodesDict:\n",
    "            return ('keep', self.__fileNodesDict[fileName])\n",
    "        elif self.__numofNode < self.__nodeNumLimit:\n",
    "            newNode = FileNode(self.__folderName, fileName, nodeData, restore = restore)\n",
    "            self.__fileNodes.append(newNode)\n",
    "            self.__fileNodesDict[newNode.getFileInfo()[0]] = newNode\n",
    "            self.__numofNode += 1\n",
    "            self.__saveFolderSystem()\n",
    "            return ('add', copy.deepcopy(newNode))\n",
    "        elif self.__numofNode >= self.__nodeNumLimit:\n",
    "            return self.__replaceNode(fileName, nodeData)\n",
    "        else:\n",
    "            raise Error('Unexpected Error - __numofNode >= __nodeNumLimit')\n",
    "            \n",
    "    def __replaceNode(self, fileName, nodeData):\n",
    "        while(True):\n",
    "            currentNode = self.__fileNodes[self.__nodePointer]\n",
    "            if(currentNode.attemptReplace()):\n",
    "                replacedNode = self.__fileNodesDict.pop(currentNode.getFileInfo()[0])\n",
    "                newNode = FileNode(self.__folderName, fileName, nodeData)\n",
    "                self.__fileNodesDict[newNode.getFileInfo()[0]] = newNode\n",
    "                self.__fileNodes[self.__nodePointer] = newNode\n",
    "                os.remove(self.__folderName + '\\\\' + replacedNode.getFileInfo()[0])\n",
    "                self.__nodePointer = (self.__nodePointer+1)%self.__nodeNumLimit\n",
    "                self.__saveFolderSystem()\n",
    "                return ('replace', copy.deepcopy(replacedNode))\n",
    "            else:\n",
    "                self.__nodePointer = (self.__nodePointer+1)%self.__nodeNumLimit\n",
    "        raise Error('Unknown Error in __replaceNode...')\n",
    "    \n",
    "    def getFileNodesByName(self, filename):\n",
    "        return self.__fileNodesDict[filename]\n",
    "    \n",
    "    def __saveFolderSystem(self):\n",
    "        with open('{0}/cacheFolderSystem-{1}.pkl'.format(self.__folderName, re.sub(r'\\W+', '', self.__folderName)), 'w') as f:\n",
    "            pickle.dump(self, f)\n",
    "    \n",
    "    def updateCacheLimit(self, newCacheLimit):\n",
    "        if (newCacheLimit < 10):\n",
    "            raise ValueError(\"The new cache limit should be larger than or equal to {0}\".format(10))\n",
    "        elif(newCacheLimit >= self.__numofNode):\n",
    "            self.__nodeNumLimit = newCacheLimit\n",
    "        elif(newCacheLimit<self.__numofNode):\n",
    "            self.__cleanUpExcessFile(newCacheLimit)\n",
    "            self.__nodeNUmLimit = newCacheLimit\n",
    "        else:\n",
    "            raise Exception(\"Unexpected error in updateCacheLimit()\")\n",
    "    \n",
    "    def getNumofNode(self):\n",
    "        return self.__numofNode\n",
    "    \n",
    "    def getNodeNumLimit(self):\n",
    "        return self.__nodeNumLimit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CacheSystem:\n",
    "    @staticmethod\n",
    "    def loadCacheSystem():\n",
    "        if(os.path.exists('cacheSystemState.pkl')):\n",
    "            print(\"Loaded saved cacheSystem in the directory: {0}\".format(os.getcwd()+'\\\\'+\"cacheSystemState.pkl\"))\n",
    "            with open('cacheSystemState.pkl', 'r') as f:\n",
    "                return pickle.load(f)\n",
    "        else:\n",
    "            print(\"The cacheSystemState does not exist...\")\n",
    "            print(\"Calling the state builder to restore the state...\")\n",
    "            return CacheSystem()\n",
    "        \n",
    "    def __init__(self, cacheLimit = 5000):\n",
    "        print(\"Initializing cachesystem...\")\n",
    "        if getPathDepth() > 1:\n",
    "            raise ValueError('The folder structure is incorrect: only allow directory with a depth of 1...')\n",
    "        self.__folderSystemDict = dict()\n",
    "        self.__cachedFile = dict()\n",
    "        self.__folderCacheLimit = cacheLimit\n",
    "        self.__restoreFolderSystem(cacheLimit)\n",
    "        self.__saveCacheSystem()\n",
    "        self.printStatus()\n",
    "        \n",
    "    def __restoreFolderSystem(self, cacheLimit):\n",
    "        print(\"Restoring folder system...\")\n",
    "        for folderName, _, files in os.walk(\".\"): \n",
    "            if folderName == \".\":\n",
    "                continue\n",
    "            self.__folderSystemDict[folderName] = FolderSystem(folderName, cacheLimit, restore = True)\n",
    "            self.__cachedFile[folderName] = dict()\n",
    "        print(\"Generated folder system...\")\n",
    "        for folderName, _, files in os.walk(\".\"): \n",
    "            if folderName == \".\":\n",
    "                continue\n",
    "            for fileName in files:\n",
    "                if \"cacheFolderSystem\" in fileName:\n",
    "                    continue\n",
    "                self.__cachedFile[folderName][fileName] = self.__folderSystemDict[folderName].getFileNodesByName(fileName)       \n",
    "\n",
    "\n",
    "    def addFile(self,folderName, fileName, nodeData):\n",
    "        currentFolderPointer = self.__createFolder(folderName)\n",
    "        addNodeResult = currentFolderPointer.addNode(fileName, nodeData)\n",
    "        if(addNodeResult[0]=='replace'):\n",
    "            print('File [{0}] in directory [{1}] is being replace...'.format(addNodeResult[1].getFileInfo()[0], folderName))\n",
    "            del self.__cachedFile[folderName][addNodeResult[1].getFileInfo()[0]]\n",
    "            self.__cachedFile[folderName][fileName] = addNodeResult[1]\n",
    "        elif(addNodeResult[0]=='keep'):\n",
    "            print('File [{0}] in directory [{1}] is already exist...'.format(addNodeResult[1].getFileInfo()[0], folderName))\n",
    "            pass\n",
    "        elif(addNodeResult[0]=='add'):\n",
    "            print('File [{0}] in directory [{1}] is added...'.format(addNodeResult[1].getFileInfo()[0], folderName))\n",
    "            self.__cachedFile[folderName][fileName] = addNodeResult[1]\n",
    "        self.__saveCacheSystem()\n",
    "  \n",
    "    def __createFolder(self, folderName):\n",
    "        if(not os.path.exists(folderName)):\n",
    "            os.makedirs(folderName)\n",
    "            newFolderSystem = FolderSystem(folderName, self.__folderCacheLimit)\n",
    "            self.__folderSystemDict[folderName] = newFolderSystem\n",
    "            self.__cachedFile[folderName] = dict()\n",
    "            print(\"The folder did not exist. A new folder [{0}] is created...\".format(folderName))\n",
    "        currentFolderPointer = self.__folderSystemDict[folderName]\n",
    "        return currentFolderPointer\n",
    "        \n",
    "        \n",
    "    def getFile(self, folderName, fileName):\n",
    "        if (folderName in self.__cachedFile) and (fileName in self.__cachedFile[folderName]):\n",
    "            return self.__cachedFile[folderName][fileName].getData()\n",
    "        else:\n",
    "            raise ValueError(\"File [{0}] in directory [{1}] not found...\".format(fileName, folderName))\n",
    "    \n",
    "    def setFolderCacheLimit(self, folderName, newCacheLimit):\n",
    "        if (folderName in self.__cachedFile):\n",
    "            self.__folderSystemDict[folderName].updateCacheLimit(newCacheLimit)\n",
    "        else:\n",
    "            raise ValueError(\"Folder not found...\".format(folderName))\n",
    "        self.__saveCacheSystem()\n",
    "    \n",
    "    def __saveCacheSystem(self):\n",
    "        with open('cacheSystemState.pkl', 'w') as f:\n",
    "            pickle.dump(self, f)\n",
    "    \n",
    "    def printStatus(self):\n",
    "        print('-------------------Cache System Status---------------------')\n",
    "        for folderName, folder in self.__folderSystemDict.items():\n",
    "            print(\"FolderName: {0} | FolderLimit: {1} | Number of node in folder: {2}\".format(folderName, folder.getNodeNumLimit(), folder.getNumofNode()))\n",
    "        print('-----------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing cachesystem...\n",
      "Restoring folder system...\n",
      "Generated folder system...\n",
      "-------------------Cache System Status---------------------\n",
      "FolderName: .\\data | FolderLimit: 5000 | Number of node in folder: 10\n",
      "FolderName: .\\Trading_table1 | FolderLimit: 5000 | Number of node in folder: 6\n",
      "FolderName: .\\Trading_table | FolderLimit: 5000 | Number of node in folder: 10\n",
      "FolderName: .\\.ipynb_checkpoints | FolderLimit: 5000 | Number of node in folder: 1\n",
      "FolderName: .\\data2 | FolderLimit: 5000 | Number of node in folder: 10\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cache = CacheSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cache.setFolderCacheLimit('.\\\\data2', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded saved cacheSystem in the directory: C:\\Users\\Henry\\Desktop\\Credit Suisse\\testfile\\cacheSystemState.pkl\n"
     ]
    }
   ],
   "source": [
    "cache = CacheSystem.loadCacheSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "FolderName: .\\data | FolderLimit: 5000 | Number of node in folder: 10\n",
      "FolderName: .\\Trading_table | FolderLimit: 5000 | Number of node in folder: 10\n",
      "FolderName: .\\.ipynb_checkpoints | FolderLimit: 5000 | Number of node in folder: 1\n",
      "FolderName: .\\data2 | FolderLimit: 5000 | Number of node in folder: 50\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "cache.printStatus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.', 'henry']"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'.\\henry'.split('\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root: [.] | folders: [['.ipynb_checkpoints', 'data', 'data2', 'Trading_table', 'Trading_table1']] | files: [['cacheSystemState.pkl', 'data.csv', 'Untitled.ipynb']]\n",
      "root: [.\\.ipynb_checkpoints] | folders: [[]] | files: [['cacheFolderSystem-ipynb_checkpoints.pkl', 'cacheFolderSystem.pkl', 'Untitled-checkpoint.ipynb']]\n",
      "root: [.\\data] | folders: [[]] | files: [['2014-01-01.pkl', '2014-01-02.pkl', '2014-01-03.pkl', '2014-01-04.pkl', '2014-01-05.pkl', '2014-01-06.pkl', '2014-01-09.pkl', '2014-01-10.pkl', '2014-01-11.pkl', '2014-01-12.pkl', 'cacheFolderSystem-data.pkl']]\n",
      "root: [.\\data2] | folders: [['data3']] | files: [['2014-01-01 - Copy (2) - Copy.pkl', '2014-01-01 - Copy (2).pkl', '2014-01-01 - Copy (3) - Copy.pkl', '2014-01-01 - Copy (3).pkl', '2014-01-01 - Copy (4) - Copy.pkl', '2014-01-01 - Copy (4).pkl', '2014-01-01 - Copy (5) - Copy.pkl', '2014-01-01 - Copy (5).pkl', '2014-01-01 - Copy (6) - Copy.pkl', '2014-01-01 - Copy (6).pkl', 'cacheFolderSystem-data2.pkl']]\n",
      "root: [.\\data2\\data3] | folders: [[]] | files: [[]]\n",
      "root: [.\\Trading_table] | folders: [[]] | files: [['cacheFolderSystem-Trading_table.pkl', 'tradingTable108.pkl', 'tradingTable109.pkl', 'tradingTable110.pkl', 'tradingTable111.pkl', 'tradingTable112.pkl', 'tradingTable122.pkl', 'tradingTable132.pkl', 'tradingTable142.pkl', 'tradingTable15.pkl', 'tradingTable16.pkl']]\n",
      "root: [.\\Trading_table1] | folders: [[]] | files: [['cacheFolderSystem-Trading_table1.pkl', 'tradingTable110.pkl', 'tradingTable111.pkl', 'tradingTable112.pkl', 'tradingTable122.pkl', 'tradingTable132.pkl', 'tradingTable142.pkl']]\n"
     ]
    }
   ],
   "source": [
    "for root, folders, files in os.walk(\".\"): \n",
    "    print('root: [{0}] | folders: [{1}] | files: [{2}]'.format(root, folders, files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
